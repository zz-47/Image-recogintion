{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26119b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIBRATION: Please keep a neutral face...\n",
      "Calibration completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# to smoothen the predictions\n",
    "expression_history = deque(maxlen=10)\n",
    "\n",
    "# calibrate\n",
    "neutral_mouth_ratio = None\n",
    "neutral_brow_ratio = None\n",
    "\n",
    "def get_points(landmarks, image_shape):\n",
    "    ih, iw = image_shape\n",
    "    return [(int(lm.x * iw), int(lm.y * ih)) for lm in landmarks.landmark]\n",
    "\n",
    "# for detecting expression \n",
    "def Detect_express(landmarks, image_shape, calibrate=False):\n",
    "    points = get_points(landmarks, image_shape)\n",
    "\n",
    "    # manipulation of 468 landmarks for expression\n",
    "    left_mouth = points[61]\n",
    "    right_mouth = points[291]\n",
    "    upper_lip = points[13]\n",
    "    lower_lip = points[14]\n",
    "    left_eyebrow = points[105]\n",
    "    right_eyebrow = points[334]\n",
    "    left_eye_top = points[159]\n",
    "    left_eye_bottom = points[145]\n",
    "    right_eye_top = points[386]\n",
    "    right_eye_bottom = points[374]\n",
    "    nose_tip = points[1]\n",
    "    chin_tip = points[152]\n",
    "\n",
    "    # cal the distances\n",
    "    mouth_width = np.linalg.norm(np.array(left_mouth) - np.array(right_mouth))\n",
    "    mouth_openness = np.linalg.norm(np.array(upper_lip) - np.array(lower_lip))\n",
    "    brow_eye_dist = abs(left_eyebrow[1] - left_eye_top[1])\n",
    "    left_eye_openness = np.linalg.norm(np.array(left_eye_top) - np.array(left_eye_bottom))\n",
    "    right_eye_openness = np.linalg.norm(np.array(right_eye_top) - np.array(right_eye_bottom))\n",
    "\n",
    "    # normalization\n",
    "    ratio = mouth_openness / mouth_width\n",
    "    brow_ratio = brow_eye_dist / mouth_width\n",
    "\n",
    "    # adaption of calibration\n",
    "    if calibrate:\n",
    "        return ratio, brow_ratio \n",
    "    \n",
    "    # comparison b/w calibrated and non-calibrated\n",
    "    mouth_change = ratio - neutral_mouth_ratio\n",
    "    brow_change = brow_ratio - neutral_brow_ratio\n",
    "\n",
    "\n",
    "    # New logic for thinking gesture: one eyebrow raised compared to the other\n",
    "    brow_diff = abs(left_eyebrow[1] - right_eyebrow[1])\n",
    "    brow_diff_threshold = 8  # tweak this threshold for sensitivity\n",
    "\n",
    "    # --- Yawning detection ---\n",
    "    # Yawning: very wide mouth open (mouth openness ratio above threshold)\n",
    "\n",
    "    yawning_threshold = 0.25\n",
    "    if ratio > yawning_threshold:\n",
    "        return \"Yawning \"\n",
    "\n",
    "    # --- Eyebrow raise detection ---\n",
    "    # Eyebrow raise: brow_eye_dist noticeably bigger than neutral\n",
    "    eyebrow_raise_threshold = 0.1\n",
    "    if brow_change > eyebrow_raise_threshold:\n",
    "        return \"Eyebrow Raised \"\n",
    "\n",
    "    # Existing expression logic\n",
    "    if mouth_change > 0.12 and brow_change > 0.05:\n",
    "        return \"Surprised\"\n",
    "    elif mouth_change > 0.08:\n",
    "        return \"Happy\"\n",
    "    elif brow_change < -0.03:\n",
    "        return \"Angry\"\n",
    "    elif (left_eyebrow[1] < right_eyebrow[1] and brow_diff > brow_diff_threshold) or \\\n",
    "         (right_eyebrow[1] < left_eyebrow[1] and brow_diff > brow_diff_threshold):\n",
    "        # One eyebrow higher than the other => Think\n",
    "        return \"Thinking ...\"\n",
    "    elif chin_tip[1] - nose_tip[1] > 30 and mouth_change < 0.02:\n",
    "        return \"Sad\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# start capturing\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set camera resolution to 1280x720\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "calibrated = False\n",
    "print(\"CALIBRATION: Please keep a neutral face...\")\n",
    "\n",
    "neutral_mouths = []\n",
    "neutral_brows = []\n",
    "\n",
    "frame_count = 0\n",
    "calibration_frames = 60\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to 1280x720 if camera does not support native resolution\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "\n",
    "    # mirror\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "        # Calculate bounding box\n",
    "        points = get_points(face_landmarks, frame.shape[:2])\n",
    "        xs = [p[0] for p in points]\n",
    "        ys = [p[1] for p in points]\n",
    "        x_min, x_max = min(xs), max(xs)\n",
    "        y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "        # Draw bounding box around the face\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "\n",
    "        if not calibrated: \n",
    "            m_ratio, b_ratio = Detect_express(face_landmarks, frame.shape[:2], calibrate=True)\n",
    "            neutral_mouths.append(m_ratio)\n",
    "            neutral_brows.append(b_ratio)\n",
    "\n",
    "            frame_count += 1\n",
    "            cv2.putText(frame, \"Calibrating... Keep a neutral face\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "            if frame_count >= calibration_frames:\n",
    "                neutral_mouth_ratio = np.mean(neutral_mouths)\n",
    "                neutral_brow_ratio = np.mean(neutral_brows)\n",
    "                calibrated = True\n",
    "                print(\"Calibration completed.\")\n",
    "            \n",
    "            # Show calibration frame and wait\n",
    "            cv2.imshow(\"Facial Expression Recognition\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue  # Skip further processing until calibration is done\n",
    "\n",
    "        # detecting expressions of calibrated face\n",
    "        expression = Detect_express(face_landmarks, frame.shape[:2])\n",
    "        expression_history.append(expression)\n",
    "\n",
    "        # smooth prediction\n",
    "        most_common = max(set(expression_history), key=expression_history.count)\n",
    "\n",
    "        # Draw expression label connected to bounding box\n",
    "\n",
    "        label = f\"Expression: {most_common}\"\n",
    "\n",
    "        # Get text size\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "\n",
    "        # Set label background rectangle coordinates (above bounding box)\n",
    "        label_y_min = max(0, y_min - text_height - baseline - 10)  # 10 pixels padding above bbox\n",
    "        label_y_max = y_min\n",
    "        label_x_min = x_min\n",
    "        label_x_max = x_min + text_width + 10  # 10 pixels padding right\n",
    "\n",
    "        # Draw filled rectangle for label background\n",
    "        cv2.rectangle(frame, (label_x_min, label_y_min), (label_x_max, label_y_max), (255, 0, 0), cv2.FILLED)\n",
    "\n",
    "        # Put expression text over the rectangle\n",
    "        cv2.putText(frame, label, (x_min + 5, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # draw face mesh\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            mp_drawing.DrawingSpec(color=(0,255,0), thickness=1, circle_radius=1)\n",
    "        )\n",
    "\n",
    "    # show frame\n",
    "    cv2.imshow(\"Facial Expression Recognition\", frame)\n",
    "\n",
    "    # key to quit\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083259f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e85401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
