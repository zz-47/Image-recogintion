{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26119b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n",
      "Loaded 0 known faces.\n",
      "CALIBRATION: Please keep a neutral face...\n",
      "Calibration completed.\n",
      "Enter name for this face:\n",
      "[INFO] Saved zeeshan to known_faces\\zeeshan.jpg\n",
      "[INFO] Updated known faces with zeeshan. Total known faces: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "# --- Setup files and folders ---\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "os.makedirs(KNOWN_FACES_DIR, exist_ok=True)\n",
    "\n",
    "# Face detector model files (assumed in same dir)\n",
    "FACE_DETECTOR_PROTO = 'deploy.prototxt.txt'\n",
    "FACE_DETECTOR_MODEL = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
    "FACE_EMBEDDING_MODEL = 'nn4.small2.v1.t7'\n",
    "\n",
    "# Load face detector and embedding model\n",
    "detector = cv2.dnn.readNetFromCaffe(FACE_DETECTOR_PROTO, FACE_DETECTOR_MODEL)\n",
    "embedder = cv2.dnn.readNetFromTorch(FACE_EMBEDDING_MODEL)\n",
    "\n",
    "# Known faces storage: names and embeddings\n",
    "known_face_names = []\n",
    "known_face_embeddings = []\n",
    "\n",
    "print(\"Loading known faces...\")\n",
    "for filename in os.listdir(KNOWN_FACES_DIR):\n",
    "    if filename.lower().endswith(('.jpg', '.png')):\n",
    "        filepath = os.path.join(KNOWN_FACES_DIR, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        if image is None:\n",
    "            print(f\"[WARN] Could not read image {filename}\")\n",
    "            continue\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "        embedder.setInput(blob)\n",
    "        vec = embedder.forward()\n",
    "        known_face_embeddings.append(vec.flatten())\n",
    "        known_face_names.append(os.path.splitext(filename)[0])\n",
    "\n",
    "# Convert to numpy array after loading all embeddings\n",
    "if known_face_embeddings:\n",
    "    known_face_embeddings = np.array(known_face_embeddings)\n",
    "else:\n",
    "    known_face_embeddings = np.empty((0, 128))  # assuming embedding size 128 for nn4.small2.v1.t7\n",
    "\n",
    "print(f\"Loaded {len(known_face_names)} known faces.\")\n",
    "\n",
    "# Mediapipe for facial expression detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "expression_history = deque(maxlen=10)\n",
    "\n",
    "neutral_mouth_ratio = None\n",
    "neutral_brow_ratio = None\n",
    "\n",
    "def get_points(landmarks, image_shape):\n",
    "    ih, iw = image_shape\n",
    "    return [(int(lm.x * iw), int(lm.y * ih)) for lm in landmarks.landmark]\n",
    "\n",
    "def Detect_express(landmarks, image_shape, calibrate=False):\n",
    "    points = get_points(landmarks, image_shape)\n",
    "    left_mouth = points[61]\n",
    "    right_mouth = points[291]\n",
    "    upper_lip = points[13]\n",
    "    lower_lip = points[14]\n",
    "    left_eyebrow = points[105]\n",
    "    right_eyebrow = points[334]\n",
    "    left_eye_top = points[159]\n",
    "    nose_tip = points[1]\n",
    "    chin_tip = points[152]\n",
    "\n",
    "    mouth_width = np.linalg.norm(np.array(left_mouth) - np.array(right_mouth))\n",
    "    mouth_openness = np.linalg.norm(np.array(upper_lip) - np.array(lower_lip))\n",
    "    brow_eye_dist = abs(left_eyebrow[1] - left_eye_top[1])\n",
    "\n",
    "    ratio = mouth_openness / mouth_width if mouth_width != 0 else 0\n",
    "    brow_ratio = brow_eye_dist / mouth_width if mouth_width != 0 else 0\n",
    "\n",
    "    global neutral_mouth_ratio, neutral_brow_ratio\n",
    "    if calibrate:\n",
    "        return ratio, brow_ratio\n",
    "\n",
    "    mouth_change = ratio - neutral_mouth_ratio if neutral_mouth_ratio is not None else 0\n",
    "    brow_change = brow_ratio - neutral_brow_ratio if neutral_brow_ratio is not None else 0\n",
    "\n",
    "    brow_diff = abs(left_eyebrow[1] - right_eyebrow[1])\n",
    "    brow_diff_threshold = 8\n",
    "\n",
    "    if mouth_change > 0.12 and brow_change > 0.05:\n",
    "        return \"Surprised\"\n",
    "    elif mouth_change > 0.08:\n",
    "        return \"Happy\"\n",
    "    elif brow_change < -0.03:\n",
    "        return \"Angry\"\n",
    "    elif brow_diff > brow_diff_threshold:\n",
    "        return \"Thinking ...\"\n",
    "    elif chin_tip[1] - nose_tip[1] > 30 and mouth_change < 0.02:\n",
    "        return \"Sad\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "def recognize_face(face_image):\n",
    "    # Prepare input blob\n",
    "    face_blob = cv2.dnn.blobFromImage(face_image, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    embedder.setInput(face_blob)\n",
    "    vec = embedder.forward().flatten()\n",
    "\n",
    "    if known_face_embeddings.shape[0] == 0:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    distances = np.linalg.norm(known_face_embeddings - vec, axis=1)\n",
    "    min_distance = np.min(distances)\n",
    "    min_index = np.argmin(distances)\n",
    "\n",
    "    if min_distance < 0.6:\n",
    "        return known_face_names[min_index]\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# --- Main loop ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "calibrated = False\n",
    "neutral_mouths = []\n",
    "neutral_brows = []\n",
    "frame_count = 0\n",
    "calibration_frames = 60\n",
    "\n",
    "print(\"CALIBRATION: Please keep a neutral face...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        continue\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    # Detect faces with OpenCV DNN detector\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "                                 (300, 300), (104.0, 177.0, 123.0))\n",
    "    detector.setInput(blob)\n",
    "    detections = detector.forward()\n",
    "\n",
    "    face_names = []\n",
    "    face_boxes = []\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Expand bounding box by 20 pixels each side (and clamp)\n",
    "            expand_px = 20\n",
    "            startX = max(0, startX - expand_px)\n",
    "            startY = max(0, startY - expand_px)\n",
    "            endX = min(w - 1, endX + expand_px)\n",
    "            endY = min(h - 1, endY + expand_px)\n",
    "\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            name = recognize_face(face)\n",
    "            face_names.append(name)\n",
    "            face_boxes.append((startX, startY, endX, endY))\n",
    "\n",
    "    # Expression detection with MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "        if not calibrated:\n",
    "            m_ratio, b_ratio = Detect_express(face_landmarks, frame.shape[:2], calibrate=True)\n",
    "            neutral_mouths.append(m_ratio)\n",
    "            neutral_brows.append(b_ratio)\n",
    "            frame_count += 1\n",
    "            cv2.putText(frame, \"Calibrating... Keep a neutral face\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            if frame_count >= calibration_frames:\n",
    "                neutral_mouth_ratio = np.mean(neutral_mouths)\n",
    "                neutral_brow_ratio = np.mean(neutral_brows)\n",
    "                calibrated = True\n",
    "                print(\"Calibration completed.\")\n",
    "        else:\n",
    "            expression = Detect_express(face_landmarks, frame.shape[:2])\n",
    "            expression_history.append(expression)\n",
    "            most_common = max(set(expression_history), key=expression_history.count)\n",
    "            cv2.putText(frame, f\"Expression: {most_common}\", (30, 100),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "            )\n",
    "\n",
    "    # Draw bounding boxes and names\n",
    "    for (startX, startY, endX, endY), name in zip(face_boxes, face_names):\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (startX, endY - 30), (endX, endY), (255, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (startX + 6, endY - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Save face on 's' key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s') and len(face_boxes) > 0:\n",
    "        startX, startY, endX, endY = face_boxes[0]\n",
    "        face_image = frame[startY:endY, startX:endX]\n",
    "        if face_image.size == 0:\n",
    "            print(\"[WARN] Face crop invalid. Not saving.\")\n",
    "        else:\n",
    "            cv2.imshow(\"Face to Save\", face_image)\n",
    "            print(\"Enter name for this face:\")\n",
    "            name = input().strip()\n",
    "            if name != \"\":\n",
    "                filepath = os.path.join(KNOWN_FACES_DIR, f\"{name}.jpg\")\n",
    "                cv2.imwrite(filepath, face_image)\n",
    "                print(f\"[INFO] Saved {name} to {filepath}\")\n",
    "\n",
    "                # Extract embedding for saved face and add to known faces list\n",
    "                face_blob = cv2.dnn.blobFromImage(face_image, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "                embedder.setInput(face_blob)\n",
    "                vec = embedder.forward().flatten()\n",
    "\n",
    "                known_face_names.append(name)\n",
    "                if known_face_embeddings.shape[0] == 0:\n",
    "                    known_face_embeddings = np.array([vec])\n",
    "                else:\n",
    "                    known_face_embeddings = np.vstack([known_face_embeddings, vec])\n",
    "\n",
    "                print(f\"[INFO] Updated known faces with {name}. Total known faces: {len(known_face_names)}\")\n",
    "\n",
    "                # Immediately update the recognized name label for this face box on current frame\n",
    "                face_names[0] = name  # <-- FIX: force update of label on current frame\n",
    "            else:\n",
    "                print(\"[WARN] No name entered. Face not saved.\")\n",
    "\n",
    "    elif key == ord('q'):  # 'q' key to quit instead of ESC\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Face Recognition & Expression Detection\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083259f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e85401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
